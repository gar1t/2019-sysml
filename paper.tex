\documentclass{article}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{listings}

\lstset{
  aboveskip=12pt,
  basicstyle=\footnotesize\ttfamily,
  breaklines=true,
  captionpos=b,
  frame=tb,
  framexbottommargin=5pt,
  framextopmargin=5pt,
}

% Use the following line for the initial blind version submitted for review:
\usepackage{sysml2019}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{sysml2019}

% The \sysmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
%\sysmltitlerunning{Guild AI: NEEDS A TITLE}

\begin{document}

\twocolumn[
\sysmltitle{Guild AI: Package management for machine learning models}

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

\begin{sysmlauthorlist}
\sysmlauthor{Garrett Smith}{guild}
\end{sysmlauthorlist}

\sysmlaffiliation{guild}{Guild AI, Chicago, Illinois, USA}

\sysmlcorrespondingauthor{Garrett Smith}{garrett@guild.ai}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\sysmlkeywords{Guild AI, SysML}

\vskip 0.3in

\begin{abstract}

  We present Guild AI, an open source toolkit that facilitates model
  reuse for application development by applying traditional software
  packaging constructs to the domain of machine learning. Package
  management strategies are central to successful software
  ecosystems. Examples include \href{https://www.npmjs.com/}{npm} for
  JavaScript, \href{https://wiki.debian.org/Apt}{APT} for Debian, and
  \href{https://pip.pypa.io}{pip} for Python. Such tools excel at
  creating traditional software packages. However, machine learning
  applications present unique requirements that call for tool
  specialization. Guild AI combines the proven effectiveness of
  package managers with novel features to enable machine learning
  model reuse for application development across a variety of use
  cases.

\end{abstract}
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \sysmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\sysmlEqualContribution} % otherwise use the standard text.

\section{Introduction}

Code reuse is a central tenet in software development and is supported
by myriad techniques, abstractions, and tools. Effective code reuse
allows developers to leverage prior work in a consistent, reliable
manner that saves time and improves software quality. In this paper we
consider code reuse in terms of \emph{packaged software} in the
context of machine learning.

\subsection{Traditional packaged software}

Packaged software is software that is organized in a way that can be
easily installed and used by \emph{users}. A user is a consumer of
software, rather than a producer or developer. A user may be software
developer, in the case of consuming software libraries or frameworks,
or she may be an end-user who uses software as a program using a
graphical or command line interface. In both cases, packaged software
may be provided in units that the user can install and start using
quickly and reliably.

This is an example of installing packaged software:

{\footnotesize
\begin{verbatim}
 $ pip install tensorflow
\end{verbatim}}

By running this command, a user is using a \emph{package manager}---in
this case the program \verb|pip|---to install a package named
\verb|tensorflow|. With this innocuous command, the user implicitly expects
a number of things:

\begin{itemize}
\item The Python module \verb|tensorflow| should be installed
\item Additional Python modules required by \verb|tensorflow| should
  also be installed
\item Installed software should work as expected on the target system
\item At a future date \verb|tensorflow| may be similarly uninstalled along
  with its no-longer-needed required packages
\item The act of installing and uninstalling \verb|tensorflow| should
  not break or otherwise destabilize other installed software on the
  target system
\end{itemize}

Such a package management facilities are essential to code reuse at
the system level. Package managers allow users to consume and manage
complex software systems with simple commands in a way that maintains
the integrity of other installed software. They support rapid
experimentation with new software as users are free to install, use,
and evaluate packages with the confidence that they can safely remove
that software later.

Package managers promote healthy software ecosystems by facilitating
software \emph{publishing}. Software authors use packaging tools to
create the installable software units---\emph{packages}---that are so
easily consumed by users. By publishing packaged software, developers
signify that their software will work as advertised if installed using
the supported tools.

Immense software ecosystems that are enabled by package managers
include Python, JavaScript, Ruby, Go, and R. The GNU/Linux operating
system itself is an ecosystem of package management ecosystems
including packaging schemes from Debian, RedHat, Gentoo, and Arch
distributions. Package managers are established cornerstones of
software reuse across languages and operating systems.

\subsection{Code reuse and machine learning models}

A \emph{machine learning model} is challenging to define as models
have different contexts. In the most general context, models are
mathematical concepts or language that represents a system
(needref). In the context of machine learning, models may be
represented by computer source code, either explicitly as declared
structures, or implicitly by way of executable instructions that
perform model related tasks. A \emph{trained model} is a model that
has learned some representation of a system through the process of
computer based optimization.

For the purpose of our discussion, a machine learning model is a
software representation of a specific mathetical concept that can be
trained by a computer. Models may be in various states:
\emph{uninitialized}, \emph{initialized}, \emph{partially trained},
\emph{fully trained}. Regardless of state, the distinguishing feature
of machine learning models for our purpose is that they support
runnable computer operations.

Models---and in particular \emph{trained models}--- are similar to
traditional software in that they can be executed to perform
computations. In fact, the purpose of training a model is to create a
computer program. The difference between a trained model and a human
authored program is one of method: a trained model is learned by an
algorithm while a human authored program is written manually.

While models may be represented in part by traditional installable
software---e.g. a TensorFlow program that imperatively defines a model
graph structure when run---models require more to be construed as
reusable code: \emph{models must be trainable on novel data}.

The remainder of this paper will outline an approach to package that
incorporates \emph{model operations} and \emph{run management} as a
central enabler of code reuse for machine learning models.

\subsection{Related Work}

\subsubsection{Model zoos}

A common approach to sharing and reusing machine learning models is a
\emph{model zoo}---an online repository of reusable models that
includes source code, examples, documentation, and in some cases
pretrained models. The \href{Caffe Model Zoo}{Caffe Model Zoo} was one
of the first model zoos and has inspired serveral others (ref).

Model zoos encourage code reuse by consolidating related models
(e.g. based on underlying library implementation or application
domain) and providing consistent documentation and repeatable methods
for using the models.

Model zoos, however, do not typically provide tools for packaging,
distributing, and using models, beyond those of publishing source code
and documentation (e.g. GitHub, web sites, etc.)

\subsubsection{TensorFlow Hub and Keras Applications}

\href{https://www.tensorflow.org/hub/}{TensorFlow Hub modules} and
\href{https://keras.io/applications/}{Keras Applications} are examples
of framework level facilities that provide a higher degree of model
reuse vis-\'a-vis model zoos. Both TensorFlow Hub modules and Keras
application support tools and patterns for packaging, distributing,
and using model source code and associated pretrained models. They
emphasize the use of \emph{transfer learning} where applicable for
training models on novel datasets.

\subsubsection{Software packages and source coderepositories}

Models are commonly reused through traditional software distribution
channels: packages and source code repositories. In both cases, model
source code is provided along with varying levels of documentation and
supporting tools. Unlike model zoos and framework packages, there is
little consistency in quality of code reuse available through these
channels. Developers are left to their own accord to find and use
available models.

\subsection{Differences}

Guild AI combines elements from model zoos, framework packages, and
traditional software channels to provide a state of the art facility
for packaging, distributing and using machine learning models.

As with model zoos, users can discover Guild AI models, including
documentation on their use. Guild AI additionally supports
installation and direct use of models through operations.

Guild AI superficially resembles TensorFlow Hub in that users can
discover, install, and use models quickly and easily. Guild AI however
differs considerably in its implementation. Guild AI does not present
a language level interface but instead defines a set of conventions
that are supported through configuration. Guild AI packaging
facilities can be applied to any machine learning model
implementation.

Guild AI also supports the well established practice of package
maintenence, where a third party can create usable packages without
necessarily coordinating with model developers. This is discussed in
detail in Section \ref{sec:package-maintainer}.

As with traditional software packages and source code repositories,
Guild AI supports a federated approach to software distriution. Users
are free to use Guild AI to create and distribute reusable models in a
variety of ways. Refer to Section \ref{sec:use-cases} for coverage of
various use case.

\section{Concepts}

This paper relies on a number of core concepts, which are defined
below.

\subsection{Projects}

A \emph{project} is a directory that contains model related
code. Model developers maintain projects for their models. Model users
maintain projects for the code that works with models, possibly
training them or otherwise incorporating them into an application.

Projects are central to model development and use. Guild AI supports
project based workflow as described in Section
\ref{sec:streamline-workflow}.

\subsection{Guild File}

A \emph{Guild file} is a plain text file containing Guild AI related
configuration. The file is named \verb|guild.yml| and is typically
located in the root directory of a Guild AI enabled project.

Listing~\ref{lst:guild-file} illustrates a simple Guild file.

\begin{lstlisting}[
    caption=Simple Guild file example,
    label={lst:guild-file}]
model: mnist
description:
  Logistic regression classifier
  of MNIST digits
operations:
  train:
    main: train_mnist
    flags:
      batchs-size: 32
      train-steps: 1000
  evaluate:
    main: eval_mnist
\end{lstlisting}

\subsection{Packages}

A Guild AI \emph{package} is a Python wheel distribution (ref) that
was generated using the \verb|guild package| command. Guild AI
packages are no different from standard Python wheel distributions and
are generated using \verb|setuptools|. However, they contain Guild AI
specific entry points that effectively publish the models they
contain.

\subsection{Models}

A \emph{model} in Guild AI is a representation of a machine learning
model that is defined in a Guild file. Models define \emph{operations}
(Section \ref{sec:operations}) that perform model related tasks such
as training or evaluating as well as \emph{resources} (Section
\ref{sec:resources}) that operations may require.

Models may be defined according to the underlying architecture or
intended use of the model. Guild AI does not prescribe any formal
meaning to the term \emph{model} or what operations are supported.

\subsection{Operations}
\label{sec:operations}

An \emph{operation} is an action that can be performed on a
model. Operations are part of a model definition.

Guild AI does not prescribe any particular set of operations that must
be defined for a model. Model developers are free to name operations
as they see fit, though Guild AI does encourage naming conventions.

The \verb|train| operation---the act of training a model from
scratch---for example, is an operation that most models
support. However, the \verb|transfer-learn| operation---the act of
transfering knowledge learned in one domain to another domain---is a
form of training, but frequently appears in Guild AI models as an
operation distinct from \verb|train|.

\subsection{Flags}

\emph{Flags} are parameters that can be set or modified by users when
they run an operation. Flags are used as inputs to the underlying code
that implements an operation.

\subsection{Resources}
\label{sec:resources}

A Guild AI \emph{resource} represents a set of source files that can
be made available as inputs to a model operation. Resources play a key
role in Guild AI's ability to effective use models. Resources can be
used to resolve project files, download files from URLs, unpack
archives, and reference files generated by other operation.

Listing~\ref{lst:resource} illustrates a resource definition for a
model. The resource \verb|idx-data| defines four source files that
will be made available to any operation that requires that resource.

\begin{lstlisting}[
    caption=Model resource example,
    label={lst:resource}]
model: mnist
resources:
  idx-data:
    description:
      MNIST dataset in compressed
      IDX format
    sources:
      - train-images-idx3-ubyte.gz
      - train-labels-idx1-ubyte.gz
      - t10k-images-idx3-ubyte.gz
      - t10k-labels-idx1-ubyte.gz
\end{lstlisting}

\subsection{Runs}

A \emph{run} is a file system artifact---specifically a directory
created and managed by Guild AI---that contains metadata and files
generated by an operation. A run may also refer to the operation
system process associated with a running operation.

Runs are described in detail in Section \ref{sec:runs}.

\subsection{Environments}

Guild AI supports \emph{environments}, which are isolated runtime
environments used for installing and using models. Guild AI supports
environments created using
\href{https://virtualenv.pypa.io}{\emph{virtualenv}}.

\subsection{Workflows}

Guild AI \emph{workflows} are patterns of model use that are enabled
by running operations in specific order. Worflows are not currently
formal constructs in Guild AI but are referenced by convention or
documented usage.

\section{Use Cases}
\label{sec:use-cases}

The package management facilities in Guild AI enable a number of use
cases, which are described below. In each case, the following roles
may be referenced:

\begin{description}
    \item[user] person using a model developed by someone else
    \item[developer] person developing a model, either from scratch or
      adapting the work of others
    \item[packager] person neither using nor developing a model but
      who packages models created by developers for use by users
\end{description}

\subsection{Publish a Model for Use}
\label{sec:publish-model}

A \emph{developer} may encourage others to use her model by
documenting the steps needed to install, adapt, and use it. She may be
motivated to simplify the user experience so that her work is more
easily and succesfully applied. The benefit to her may be quality
feedback from expert users, improved reputation, a sense of
contribution, or her colleagues may simply expect that work be
documented and easy to use.

While documenting the steps needed to use a model is undoubtedly
helpful, the process is still burdensome for both the developer and
her users. Guild AI can be used to simultaenously document model use
but also directly support its use through model operations.

Consider these instructions for model use, which might be documented
for a project:

\begin{enumerate}
   \item Install required packages
   \item Download the raw data
   \item Prepare the raw data for training
   \item Train the model
   \item Export the trained model for deployment
\end{enumerate}

While these steps provide invaulable information, they still rely on
the user to carefully execute them and troubleshoot issues as they
arise. The process takes time and is subject to error at any step.

Guild AI can be used to both document and automate these
steps. Listing~\ref{lst:published-model} illustrates a Guild file that
might be used to codify the steps as model operations.

\begin{lstlisting}[
    caption=Sample project Guild file,
    label={lst:published-model}]
model: sample
operations:
  prepare-data:
    description:
      Prepare data for training
    main: prepare_data
    requires: raw-data
  train:
    description: Train model
    main: train
    requires: prepared-data
  export-model:
    description:
      Export model for deployment
    main: export_model
    requires: trained-model
resources:
  raw-data:
    description: Raw data for training
    sources:
      - url: http://mydata.com/raw.tgz
  prepare-data:
    description: Prepared data
    sources:
      - operation: prepare-data
  trained-model:
    description: Trained model
    sources:
      - operation: train
\end{lstlisting}

The operations can be run using the Guild AI command line interface as
follows:

{\footnotesize
\begin{verbatim}
 $ guild run prepare-data
 $ guild run train
 $ guild run export-model
\end{verbatim}}

Furthermore, Guild AI provides model help, detailing available
operations, supported flags, and operation dependencies.

A user can get help for the model by running:

{\footnotesize
\begin{verbatim}
 $ guild help
\end{verbatim}}

Documentation is automatically generated from the model description,
making Guild AI models self documenting.

The developer can chose to distribute her model as a
project---e.g. making it available as a GitHub repository. She may
alternatively package the model and deploy as an installable Python
wheel distribution artifact.

\subsection{Use a Published Model}

The flip side of the use case outline in
Section~\ref{sec:publish-model} is that of the \emph{user}. A user is
interesting in taking the work of a model developer and applying it,
either by adapating her model to a new application or by integrating
it as into another project.

Users commonly rely on thorough documentation to effectively use
models. If a project is under documented or otherwise hard to work
with, it may not be used. This is a lost opportunity for both user and
developer that hinders adoption and model improvement.

As described in Section~\ref{sec:publish-model}, a published model is
simple to use. From the standpoint of the user, the model can be used
either by cloning the project repository---e.g. as in the case of
GitHub published models---or install the model as a Python
package. Assuming the project was published as a package named
\verb|sample-project|, the user might run these commands to use the
model:

\setlength{\parindent}{1em}

{\footnotesize\emph{Install the package}}

{\footnotesize
\begin{verbatim}
 $ guild install sample-project
\end{verbatim}}

{\footnotesize\emph{View package help}}

{\footnotesize
\begin{verbatim}
 $ guild help sample-package
\end{verbatim}}

{\footnotesize\emph{Use the model}}

{\footnotesize
\begin{verbatim}
 $ guild run sample:prepare-data
 $ guild run sample:train
 $ guild run sample:export-model
\end{verbatim}}

\setlength{\parindent}{0em}

This illustrates the usefulness of packaging models for
reuse. Packaged models in this case consist of more than the
underlying model code---they include additional information that makes
them trivial to use relative to traditional forms of model reuse.

\subsection{Package Third Party Models}
\label{sec:package-maintainer}

Complex software ecosystems such as GNU/Linux have formalized the role
of a software \emph{packager} (or \emph{package maintainer}). The goal
of a packager is to improve the value of a software distribution by
creating high quality software packages that users find
useful. Packers are often independent of the upstream software
projects they package, serving as intermediaries betweeen the software
developers and distribution users.

Guild AI supports this pattern by allowing packagers to incorporate
upstream model sources into Guild packages, patching them as needed to
provide the desired functionality to users.

Consider a case where a model developer is overloaded with research
tasks and doesn't have time to provide documentation for using her
models or publishing them for use as described in
Section~\ref{sec:publish-model}. An independent \emph{packager} may
step up to create a package instead.

A packager must assume that upstream sources are available \emph{as
  is} and he cannot expect developers to fix bugs or add new features
(though he may certainly ask and hope). Packagers therefore must be
prepared to \emph{patch} model code as needed to get it to work as
expected.

Guild AI provides various means of patching model source to support
packagers in this role.

\subsection{Team Collaboration}

The roles of \emph{developer}, \emph{user}, and \emph{packager} often
exist within a single organization or team. Guild AI supports team
collaboration by supporting each role as a separate concern.

Within a typical organization structure, the roles map as follows:

\setlength{\parindent}{1em}
developer $\rightarrow$ \emph{research scientist}

user $\rightarrow$ \emph{software engineer}

packager $\rightarrow$ \emph{research engineer}
\setlength{\parindent}{0em}

Of course this is a rough mapping and not all organizations share this
structure. Whatever the job titles and division of labor, Guild AI
supports the three facets of collaboration: model development, model
use, and intermediation between those two points in the interest of
freeing up developer time and resources to focus on pure model
development.

\subsection{Streamline Model Developer Workflow}
\label{sec:streamline-workflow}

In the case of a single developer who has no interest in publishing
models or otherwise supporting users, Guild AI model abstractions
provide value. By implementing models as units of operations, as is
the case with Guild AI model packaging, developers ensure their models
are easy to use from the early stages of development. This streamlines
the development process as developers can repeatedly run and iterate
through model operations using high level commands with well defined,
self documenting interfaces.

\subsection{Manage Run Artifacts}

\section{Using Models}

\subsection{Packaged Models}

\subsection{Project Models}

\subsection{Listing Available Models and Operations}

\subsection{Getting Help for Models}

\subsection{Running Operations}

\subsection{Viewing and Comparing Runs}

\subsection{Exporting Model Artifacts}

\section{Managing Runs}
\label{sec:runs}

- What is a run (from an operation)

- What is a run concretely (i.e. directory, etc.)

\subsection{Starting a Run}

\subsection{Listing Runs}

\subsection{Getting Run Information}

\subsection{Deleting Runs}

\subsection{Archiving and Restoring Runs}

\subsection{Run Dependencies}

\subsection{Remote Runs}

\section{Developing Reusable Models}

\subsection{Developing a Model from Scratch}

- How to choose a model boundary?

- How to define operations

\subsection{Customizing Models}

\subsubsection{Model Inheritance}

\subsubsection{Configuration Mixins}

\subsubsection{Modifying Operations}

\subsubsection{Modifying Flag Values}

\subsubsection{Reusing Python Main Modules}

\subsection{Packaging}

\subsection{Patching Strategies}

\section{Implementation}

- Core - written in Python, etc.

\subsection{Command Line Interface}

\subsection{Configuration Processing}

\subsection{Resource Resolution}

\subsection{Model Testing}

\subsection{Packaging and Distribution}

\subsection{Run Indexing}

\subsection{Run Visualization}

\subsection{Remote Environments}

\section{Status}

- Apache 2.0

\subsection{History and Lessons Learned}

- Workshops
- User feedback

\subsection{Packages}

- slim, object-detection, mnist, hello

\subsection{Early Use}

\section{Summary}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Typography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Delete this to end of doc
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Verbatim}

{\footnotesize
\begin{verbatim}
dvips -Ppdf -tletter -G0 -o paper.ps paper.dvi
ps2pdf paper.ps
another line yo
\end{verbatim}}

You can copy the file by running \verb|cp foo bar| where \textit{foo}
is some file you want to copy and \textit{bar} is something else.

\subsection{Italics}

\textit{Proceedings of the $\mathit{2}^{nd}$ SysML Conference}

And \emph{this is for emphasis!}

\subsection{Bold}

I will \textbf{make this bold} yo.

\subsection{Teletype}

Set the value to \texttt{accepted} and everything will be okay.

\subsection{Dots}

ldots: \ldots

dots: \dots

\subsection{Less than, greater than}

\textless{}email@domain.com\textgreater{}

\subsection{Footnotes}

You can use footnotes\footnote{Footnotes should be complete
  sentences.} which will be super awesome. Don't ask me how it works.

\subsection{Tables}

\begin{table}[t]
  \caption{Classification accuracies for naive Bayes and flexible
    Bayes on various data sets.}
  \label{sample-table}
  \begin{center}
    \begin{small}
      \begin{sc}
        \begin{tabular}{lcccr}
          \toprule
          Data set & Naive & Flexible & Better? \\
          \midrule
          Breast    & 95.9$\pm$ 0.2& 96.7$\pm$ 0.2& $\surd$ \\
          Cleveland & 83.3$\pm$ 0.6& 80.0$\pm$ 0.6& $\times$\\
          Glass2    & 61.9$\pm$ 1.4& 83.8$\pm$ 0.7& $\surd$ \\
          Credit    & 74.8$\pm$ 0.5& 78.3$\pm$ 0.6&         \\
          Horse     & 73.3$\pm$ 0.9& 69.7$\pm$ 1.0& $\times$\\
          Meta      & 67.1$\pm$ 0.6& 76.5$\pm$ 0.5& $\surd$ \\
          Pima      & 75.1$\pm$ 0.6& 73.9$\pm$ 0.5&         \\
          Vehicle   & 44.9$\pm$ 0.6& 61.5$\pm$ 0.4& $\surd$ \\
          \bottomrule
        \end{tabular}
      \end{sc}
    \end{small}
  \end{center}
  \vskip -0.1in
\end{table}

Table \ref{software-vs-models} compares traditional software with
reusable models.

\begin{table}[h!]
  \begin{center}
    \caption{Traditional software vs reusable models.}
    \label{software-vs-models}
    \begin{small}
      \begin{tabular}{l|l}
        \toprule
        \textbf{Traditional software} & Installed code \\ \hline
        \textbf{Reusable models} & Installed code + trainable on novel data \\
        \bottomrule
      \end{tabular}
    \end{small}
  \end{center}
\end{table}

\subsection{Citations}

I really like TensorFlow \cite{tensorflow2015-whitepaper}.

\bibliography{paper}
\bibliographystyle{sysml2019}

\end{document}
